{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Traffic Sign Recognition** \n",
    "\n",
    "---\n",
    "\n",
    "**Build a Traffic Sign Recognition Project**\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "* Load the data set (see below for links to the project data set)\n",
    "* Explore, summarize and visualize the data set\n",
    "* Design, train and test a model architecture\n",
    "* Use the model to make predictions on new images\n",
    "* Analyze the softmax probabilities of the new images\n",
    "* Summarize the results with a written report\n",
    "\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./examples/visualization.png \"Visualization\"\n",
    "[image2]: ./examples/loss.png \"Loss\"\n",
    "[image3]: ./examples/valid_acc.png \"Validation accuracy\"\n",
    "[image4]: ./examples/confushion_matrix.png \"Confushion matrix\"\n",
    "[image5]: ./examples/false_predictions.png \"False predictions\"\n",
    "[image6]: ./examples/web_examples.png \"German Traffic Signs\"\n",
    "[image7]: ./examples/web_examples_prediction.png \"German Traffic Signs Prediction\"\n",
    "[image8]: ./testimages/test1.JPG \"Visual of feature maps\"\n",
    "[image9]: ./examples/feature_maps.png \"Visual of feature maps\"\n",
    "\n",
    "---\n",
    "## Data Set Summary & Exploration\n",
    "\n",
    "### 1. Data Set Summary.\n",
    "\n",
    "Summary statistics of the traffic signs data set:\n",
    "\n",
    "* Number of training examples = 34799\n",
    "* Number of testing examples = 12630\n",
    "* Image data shape = (32, 32, 3)\n",
    "* Number of classes = 43\n",
    "\n",
    "### 2. Visualization:\n",
    "\n",
    "Here is an exploratory visualization of the data set. It is a bar chart showing the number of train and validation images in each class. Note that, test data still remain undiscovered. \n",
    "\n",
    "![alt text][image1]\n",
    "\n",
    "---\n",
    "## Design and Test a Model Architecture\n",
    "\n",
    "### 1. Preprocessed the image data:\n",
    "In this project, only normalization is used to preprocess data. Normalization help saving trainning time and help model perform better in case features in images have diferrent mean and std\n",
    "\n",
    "### 2. Describe what your final model architecture looks like including model type, layers, layer sizes, connectivity, etc.) Consider including a diagram and/or table describing the final model.\n",
    "\n",
    "My final model consisted of the following layers:\n",
    "\n",
    "| Layer         \t\t\t\t|     Description\t  \t      \t\t\t\t\t\t\t| \n",
    "|:-----------------------------:|:-----------------------------------------------------:|\n",
    "| Input         \t\t\t\t| 32x32x3 RGB image   \t\t\t\t\t\t\t\t\t|\n",
    "| Convolution 5x5x3     \t\t| 1x1 stride, output depth: 6, outputs 28x28x6\t|\n",
    "| RELU\t\t\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Max pooling\t     \t\t \t| 2x2 stride, outputs 14x14x6\t \t\t\t\t\t\t|\n",
    "| Convolution 5x5x6  \t\t   \t| 1x1 stride, output depth: 16, outputs 10x10x16\t|\n",
    "| RELU\t\t\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Max pooling\t      \t\t\t| 2x2 stride, outputs 5x5x16\t \t\t\t\t\t\t|\n",
    "| Flatten\t    \t\t\t\t| Outputs 400      \t\t\t\t\t\t\t\t|\n",
    "| Fully connected\t\t\t\t| Outputs 120        \t\t\t\t\t\t\t\t|\n",
    "| Fully connected\t\t\t\t| Outputs 84        \t\t\t\t\t\t\t\t|\n",
    "| Fully connected\t\t\t\t| Outputs 43        \t\t\t\t\t\t\t\t|\n",
    "\n",
    "\n",
    "\n",
    "### 3. Trained model:\n",
    "\n",
    "Batch size and epochs:\n",
    "* EPOCHS = 500\n",
    "* BATCH_SIZE = 128\n",
    "\n",
    "Hyperparameters:\n",
    "* mu = 0\n",
    "* sigma = 0.1\n",
    "\n",
    "Trainning:\n",
    "* rate = 0.001\n",
    "* optimizer = tf.train.AdamOptimizer()\n",
    "\n",
    "Trainning process:\n",
    "loss:\n",
    "\n",
    "![alt text][image2]\n",
    "\n",
    "Validation accuracy:\n",
    "\n",
    "![alt text][image3]\n",
    "\n",
    "### 4. Choosing Final Model:\n",
    "\n",
    "Final model results:\n",
    "\n",
    "* Validation Accuracy = 0.961\n",
    "* Test Accuracy = 0.942\n",
    "\n",
    "To get the final result, hyper parametters are twisted with defferent values. In addition, the initial weights and trainning image order will also effect the result since loss function are non convex and there is no guarantee to reach global minimum. So, with the same parametters, restarting the trainning process (reinitialize weights) also will yeild different results.\n",
    "\n",
    "Confushion matrix:\n",
    "\n",
    "![alt text][image4]\n",
    "\n",
    "Based on confushion matrix. We can see some of highest false prediction rate:\n",
    "\n",
    "![alt text][image5]\n",
    "\n",
    "---\n",
    "\n",
    "## Test a Model on New Images\n",
    "\n",
    "### 1.  German traffic signs found on the web:\n",
    "\n",
    "![alt text][image6]\n",
    "\n",
    "\n",
    "### 2. Model's predictions on these new traffic signs:\n",
    "Results of the prediction:\n",
    "\n",
    "![alt text][image7]\n",
    "\n",
    "\n",
    "The model accuracy on new images:\n",
    "New images test accuracy = 100.00%\n",
    "\n",
    "### 3. Softmax probabilities:\n",
    "\n",
    "For most of test images, model are very sure about the probability of image being corrected label ( probability ~= 1.).\n",
    "\n",
    "Here is example of the 5 highest softmax probabilities of the first images: \n",
    "\n",
    "| Probability         \t|     Prediction\t        \t\t\t\t\t| \n",
    "|:---------------------:|:---------------------------------------------:| \n",
    "| 1.         \t\t\t| Right-of-way at the next intersection   \t\t| \n",
    "| 0.     \t\t\t\t| Speed limit (20km/h) \t\t\t\t\t\t\t|\n",
    "| 0.\t\t\t\t\t| Speed limit (30km/h)\t\t\t\t\t\t\t|\n",
    "| 0.\t      \t\t\t| Speed limit (50km/h)\t\t\t\t\t \t\t|\n",
    "| 0.\t\t\t\t    | Speed limit (60km/h)      \t\t\t\t\t|\n",
    "\n",
    "\n",
    "## Visualizing the Neural Network\n",
    "### 1. Visual output of trained network's feature maps:\n",
    "Here is the visual output of trained network's feature maps on first convolutional layer. We can see the all the edges and color of image are activated:\n",
    "Input:\n",
    "![alt text][image8]\n",
    "Feature maps:\n",
    "![alt text][image9]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
